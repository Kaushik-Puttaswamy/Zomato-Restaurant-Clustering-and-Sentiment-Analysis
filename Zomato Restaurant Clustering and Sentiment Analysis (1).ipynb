{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a647be37-03a7-4216-bec8-8aa5d4e0259d",
   "metadata": {},
   "source": [
    "***Zomato Restaurant Clustering and Sentiment Analysis***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167266e-990c-484b-b0eb-3d2d917d0ac2",
   "metadata": {},
   "source": [
    "# **Project Summary -**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b4c90-81bf-457e-b2bb-f4af30c6e86b",
   "metadata": {},
   "source": [
    "This project entailed the utilization of advanced data analytics techniques to gain a deeper understanding of the restaurants and customer feedback on the popular online food delivery platform, Zomato.\n",
    "\n",
    "The data procured included information such as the restaurant's name, location, cuisines, average cost for two, ratings, and user reviews.\n",
    "\n",
    "Subsequently, I embarked on the task of data cleaning and preprocessing, which involved the elimination of duplicate entries, addressing missing values, and transforming the data into a format amenable to analysis.\n",
    "\n",
    "The next step in the project was the implementation of clustering on the restaurant data through the use of the k-means algorithm. The objective of the clustering was to group similar restaurants together and discern patterns within the data. The features employed for the clustering process included the restaurant's location, cuisines, and average cost for two. The number of clusters was determined by utilizing the elbow method.\n",
    "\n",
    "I then proceeded to conduct sentiment analysis on the user reviews to gain a comprehensive understanding of the overall sentiment towards the restaurants. Certain libraries were utilized to classify the reviews as positive, negative, or neutral. Additionally, I extracted the most recurrent words utilized in the reviews and visualized them through the creation of word clouds.\n",
    "\n",
    "The outcome of the analysis revealed that the restaurants within the city were grouped into five clusters based on their location, cuisines, and average cost for two. The sentiment analysis uncovered that, generally, customers held a positive sentiment towards the restaurants.\n",
    "\n",
    "In conclusion, this project exemplifies the utility of clustering and sentiment analysis in gaining a more profound comprehension of restaurant data on Zomato. The insights procured from the analysis can be of immense benefit to both restaurants and customers in making informed decisions. Furthermore, the project can be extended to other cities or even countries to gain insight into the eating habits and preferences of individuals in different regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f60bd-cb34-408f-92db-b3a4a5b5a073",
   "metadata": {},
   "source": [
    "# **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c229d-8c24-4485-8b9b-613afce12626",
   "metadata": {},
   "source": [
    "The problem statement for this project is to analyze and understand the restaurant industry in India by utilizing data from the Indian restaurant aggregator and food delivery start-up, Zomato. The project aims to gain insights into the sentiments of customer reviews, cluster Zomato restaurants into different segments, and analyze the data to make useful conclusions in the form of visualizations. The data analyzed includes information on cuisine, costing, and customer reviews. The project aims to assist customers in finding the best restaurant in their locality and aid the company in identifying areas for growth and improvement in the industry. Additionally, the project aims to use the data for sentiment analysis and identifying critics in the industry through the metadata of reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfd05a-8838-4a0d-b82d-40d547f69adc",
   "metadata": {},
   "source": [
    "## ***1. Know Your Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcdd8234-b30f-4b9c-92f2-565db71fab9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2881843322.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 31\u001b[1;36m\u001b[0m\n\u001b[1;33m    from sklearn.naive bayes import MultinomialNB\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, precision_score, recall_score, f1_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "#importing kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#importing random forest and XgB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Non-negative matrix Factorization \n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.naive bayes import MultinomialNB\n",
    "\n",
    "#principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Silhouette score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "#importing stopwords \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#for tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#for POS tagging(Part of sppech in NLP sentiment analysis)\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#import stemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#import tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#LDA\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#import contraction\n",
    "!pip install contractions\n",
    "!pip install gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "#importing shap for model expainability\n",
    "!pip install shap\n",
    "import shap\n",
    "\n",
    "#download small spacy model\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# import spacy\n",
    "\n",
    "#The following lines adjust the granularity of reporting.\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10931b8a-779c-4ab7-821f-935747971df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.3-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\unique\\anaconda3\\lib\\site-packages (from wordcloud) (10.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\unique\\anaconda3\\lib\\site-packages (from wordcloud) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\unique\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.3-cp312-cp312-win_amd64.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 20.5/301.4 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 194.6/301.4 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 301.4/301.4 kB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d0c0b-07ea-4c19-9142-4f16fca0afea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e631d-6010-449b-93c7-9346c04a3421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
